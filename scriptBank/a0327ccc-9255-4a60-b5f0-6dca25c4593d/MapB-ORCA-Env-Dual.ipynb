{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Data comes from **MIG/DualData**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple\n",
    "from argparse import ArgumentParser\n",
    "from path import Path\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# File name / Environment / Crowd / AI\n",
    "Simset = namedtuple(\"Simset\", [\"Name\",\"Envs\",\"Crowd\",\"AI\"])\n",
    "boolmap = lambda x:bool(int(x))\n",
    "Situs = [\n",
    "    Simset(\"All\", *map(boolmap,\"111\")),\n",
    "    Simset(\"Environment\", *map(boolmap,\"100\")),\n",
    "    Simset(\"Crowd\", *map(boolmap,\"010\")),\n",
    "    Simset(\"AI\", *map(boolmap,\"001\")),\n",
    "]\n",
    "\n",
    "current = Situs[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseLogfile(filename):\n",
    "    benchmark = pd.read_table(filename, sep=' ', skiprows=1)\n",
    "    benchmark = benchmark[benchmark[\"frames\"] < benchmark[\"frames\"].max()]\n",
    "    \n",
    "    value_col_names = [\"hashing\", \"time_avg\", \"len_avg\", \"ple_avg\", \"cls_avg\"]\n",
    "    col_names = [col_name for col_name in benchmark.columns if \n",
    "        (col_name.endswith(\"th_obstacle\") and current.Envs) or\n",
    "        (col_name.endswith(\"th_region\") and current.Crowd) or\n",
    "        (col_name.endswith(\"th_ai\") and current.AI)]\n",
    "    \n",
    "    # Modifing & extracting datas\n",
    "    benchmark.loc[:, \"hashing\"] = benchmark[col_names].apply(\n",
    "        lambda x: hash(tuple(x)),axis=1)\n",
    "    benchmark.loc[:, \"time_avg\"] = (\n",
    "        benchmark[\"agent_time_enableds\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "    benchmark.loc[:, \"len_avg\"] = (\n",
    "        benchmark[\"agent_distance_traveleds\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "    benchmark.loc[:, \"ple_avg\"] = (\n",
    "        benchmark[\"agent_ple_energys\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "    benchmark.loc[:, \"cls_avg\"] = (\n",
    "        benchmark[\"collisionTimes\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "\n",
    "    sampleSet = benchmark[col_names + value_col_names]\n",
    "    sample1, sample2 = sampleSet.iloc[::2], sampleSet.iloc[1::2]\n",
    "\n",
    "    sample1.set_index('hashing', inplace=True)\n",
    "    sample2.set_index('hashing', inplace=True)\n",
    "    \n",
    "    print(\"Dual trail\")\n",
    "    print( (sample1-sample2).dropna().apply(np.std, ddof=1)\n",
    "      .loc[value_col_names[1:]].to_frame() )\n",
    "    \n",
    "    print(\"Varience test\")\n",
    "    print(sampleSet.apply(np.std, ddof=1).loc[value_col_names[1:]].to_frame())\n",
    "    \n",
    "    print(\"Mean Value test\")\n",
    "    print(sampleSet.apply(np.mean).loc[value_col_names[1:]].to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaidong/logfiles/MapA-SF-Env.log\n",
      "--------------------\n",
      "Dual trail\n",
      "           0\n",
      "time_avg NaN\n",
      "len_avg  NaN\n",
      "ple_avg  NaN\n",
      "cls_avg  NaN\n",
      "Varience test\n",
      "                  0\n",
      "time_avg   5.719305\n",
      "len_avg    7.132128\n",
      "ple_avg   24.146009\n",
      "cls_avg    3.061273\n",
      "Mean Value test\n",
      "                   0\n",
      "time_avg   84.217697\n",
      "len_avg   102.188417\n",
      "ple_avg   350.782949\n",
      "cls_avg     4.929612\n",
      "\n",
      "\n",
      "\n",
      "/home/kaidong/logfiles/MapB-ORCA-Env.log\n",
      "--------------------\n",
      "Dual trail\n",
      "                 0\n",
      "time_avg  1.387171\n",
      "len_avg   1.287551\n",
      "ple_avg   5.761329\n",
      "cls_avg   1.479116\n",
      "Varience test\n",
      "                  0\n",
      "time_avg   3.656902\n",
      "len_avg    4.096479\n",
      "ple_avg   14.608961\n",
      "cls_avg    2.236466\n",
      "Mean Value test\n",
      "                   0\n",
      "time_avg  107.380873\n",
      "len_avg   136.671736\n",
      "ple_avg   464.565396\n",
      "cls_avg    14.206392\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in Path(\"/home/kaidong/logfiles\").glob(\"*Env*\"):\n",
    "    print(file) \n",
    "    print(\"-\"*20)\n",
    "    \n",
    "    parseLogfile(file)\n",
    "    print(\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
