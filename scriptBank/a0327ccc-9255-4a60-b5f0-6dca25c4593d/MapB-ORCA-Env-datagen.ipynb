{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Data comes from **MIG/DualData**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple\n",
    "from argparse import ArgumentParser\n",
    "from path import Path\n",
    "from IPython.display import display\n",
    "from xilio import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# File name / Environment / Crowd / AI\n",
    "Simset = namedtuple(\"Simset\", [\"Name\",\"Envs\",\"Crowd\",\"AI\"])\n",
    "boolmap = lambda x:bool(int(x))\n",
    "Situs = [\n",
    "    Simset(\"All\", *map(boolmap,\"111\")),\n",
    "    Simset(\"Environment\", *map(boolmap,\"100\")),\n",
    "    Simset(\"Crowd\", *map(boolmap,\"010\")),\n",
    "    Simset(\"AI\", *map(boolmap,\"001\")),\n",
    "]\n",
    "\n",
    "current = Situs[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseLogfile(filename, multi=False):\n",
    "    benchmark = pd.concat(\n",
    "    [pd.read_table(file, sep=' ', skiprows=1) for file in filename],\n",
    "    ignore_index = True) if multi else pd.read_table(filename, sep=' ', skiprows=1)\n",
    "    benchmark = benchmark[benchmark[\"frames\"] < benchmark[\"frames\"].max()]\n",
    "    \n",
    "    value_col_names = [\"hashing\", \"time_avg\", \"len_avg\", \"ple_avg\", \"cls_avg\"]\n",
    "    col_names = [col_name for col_name in benchmark.columns if \n",
    "        (col_name.endswith(\"th_obstacle\") and current.Envs) or\n",
    "        (col_name.endswith(\"th_region\") and current.Crowd) or\n",
    "        (col_name.endswith(\"th_ai\") and current.AI)]\n",
    "    \n",
    "    # Modifing & extracting datas\n",
    "    benchmark.loc[:, \"hashing\"] = benchmark[col_names].apply(\n",
    "        lambda x: hash(tuple(x)),axis=1)\n",
    "    benchmark.loc[:, \"time_avg\"] = (\n",
    "        benchmark[\"agent_time_enableds\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "    benchmark.loc[:, \"len_avg\"] = (\n",
    "        benchmark[\"agent_distance_traveleds\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "    benchmark.loc[:, \"ple_avg\"] = (\n",
    "        benchmark[\"agent_ple_energys\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "    benchmark.loc[:, \"cls_avg\"] = (\n",
    "        benchmark[\"collisionTimes\"].apply(\n",
    "        lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float).mean()))\n",
    "\n",
    "    sampleSet = benchmark[col_names + value_col_names]\n",
    "    sample1, sample2 = sampleSet.iloc[::2], sampleSet.iloc[1::2]\n",
    "\n",
    "    sample1.set_index('hashing', inplace=True)\n",
    "    sample2.set_index('hashing', inplace=True)\n",
    "    \n",
    "    print(\"Dual trail\")\n",
    "    dual = ((sample1-sample2).dropna().apply(np.std, ddof=1)\n",
    "      .loc[value_col_names[1:]])\n",
    "    print(dual)\n",
    "    print(len(dual))\n",
    "    \n",
    "    print(\"Varience test\")\n",
    "    print(sampleSet.apply(np.std, ddof=1).loc[value_col_names[1:]].to_frame())\n",
    "    \n",
    "    print(\"Mean Value test\")\n",
    "    print(sampleSet.apply(np.mean).loc[value_col_names[1:]].to_frame())\n",
    "    \n",
    "    return sampleSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/Users/kaidong/logfiles/MapB-ORCA-Env-4.log'),\n",
       " Path('/Users/kaidong/logfiles/MapB-ORCA-Env-2.log'),\n",
       " Path('/Users/kaidong/logfiles/MapB-ORCA-Env-3.log'),\n",
       " Path('/Users/kaidong/logfiles/MapB-ORCA-Env-1.log')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Path(\"/Users/kaidong/logfiles\").files()\n",
    "f  # Those three files are used for the env gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual trail\n",
      "time_avg    1.393265\n",
      "len_avg     1.252040\n",
      "ple_avg     5.280296\n",
      "cls_avg     1.458689\n",
      "dtype: float64\n",
      "4\n",
      "Varience test\n",
      "                  0\n",
      "time_avg   3.666536\n",
      "len_avg    4.158294\n",
      "ple_avg   14.720363\n",
      "cls_avg    2.249365\n",
      "Mean Value test\n",
      "                   0\n",
      "time_avg  107.397961\n",
      "len_avg   136.730050\n",
      "ple_avg   464.706657\n",
      "cls_avg    14.145722\n"
     ]
    }
   ],
   "source": [
    "ss = parseLogfile(f, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA Generation\n",
    "\n",
    "col_names = [col_name for col_name in ss.columns if \n",
    "        (col_name.endswith(\"th_obstacle\") and current.Envs) or\n",
    "        (col_name.endswith(\"th_region\") and current.Crowd) or\n",
    "        (col_name.endswith(\"th_ai\") and current.AI)]\n",
    "\n",
    "sn = ss.as_matrix(col_names)\n",
    "for i in [x for x in ss.columns if x.endswith(\"avg\")]:\n",
    "    st = ss.as_matrix((i,))\n",
    "    dump(\n",
    "        Path(\".\")/i,\n",
    "        {\n",
    "            \"X\": sn,\n",
    "            \"Y\": st,\n",
    "            \"info\": \"ORCA Map2 Env \" + i[:-4]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32014"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
